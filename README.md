[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://github.com/EngAhmedHady/CoGenerator/blob/main/LICENSE)
# BSA Data AnalysisTool for LDA measurements
This repository contains a Python script designed to process and analyze joining points‚Äîthat is, LDA data collected at the same physical location but recorded in separate acquisition files. The data originates from Excel files generated by Dantec‚Äôs BSA software. The script computes key statistical measures and optionally visualizes velocity distributions through histograms.

## üìÑ Overview

The script performs the following tasks:

- Loads multiple Excel files containing LDA measurement data.
- Filters velocity components based on defined valid ranges.
- Computes key statistics including:
  - Data acquisition duration and rates
  - Mean and RMS velocities
  - Confidence intervals
- Applies optional Gaussian Mixture Model (GMM) weighting.
- Plots histograms for velocity component distributions.

## üìÇ Input Files

Excel files are expected to follow this structure:
- Filenames: `main_file_name + suffix + .xlsx` (e.g., `TestRun001.xlsx`)
- Data starts after 5 header rows.
- Column names for 1D LDA:
  - `"AT [ms]"`
  - `"TT [¬µs]"`
  - `"LDA1 [m/s]"`
- Column names for 2D LDA (second component):
  - `"AT{2} [ms]"`
  - `"TT{2} [¬µs]"`
  - `"LDA2{2} [m/s]"`

## üì¶ Dependencies

Install the required Python libraries:

```bash
pip install numpy pandas matplotlib xlwings scipy
```

## üöÄ How to Use

### Parameters:

| Parameter         | Type       | Description |
|------------------|------------|-------------|
| `directory_path` | `str`      | Directory containing Excel files |
| `main_file_name` | `str`      | Base filename (without suffix or extension) |
| `file_suffixes`  | `list[str]`| List of suffixes to identify runs |
| `num_components` | `int`      | 1 or 2 for the number of LDA components |
| `vx_range`       | `list[float]`, optional | Range to filter LDA1 velocities |
| `vy_range`       | `list[float]`, optional | Range to filter LDA2 velocities |
| `GMMx_weights`   | `list`, optional | GMM params: `[means, stds, weights]` |

## Example Usage

This tutorial demonstrates how to use the `LDA_statistics_v2` module for processing LDA data files. The example below shows a complete script to load, analyze, and export statistics from LDA measurements.

```python
import os
import numpy as np
import LDA_statistics_v2 as LDA

if __name__ == '__main__':
    # Define your inputs
    directory = r'DataEx'
    base_file = 'TestRun'
    suffixes_set = [
                    ['014', '015', '040'],
                    ['029', '030', '049', '054'],
                    ['037', '038'],
                   ]
    num_comps = 2 # Change to 1 for one-component analysis

    # Optional: Define velocity ranges for filtering
    # Example filtering or weighting if needed
    vx_filter_range = [None, [150, 300], None] # U-component
    vy_filter_range = None # No filtering for V-component
    wy = None
    wx = [
          [
           # mean velocity of existing two peaks, if more add the means
           np.array([221.45906043, 125.73081386]),
           # standard deviation of each peak, should be in the same length and positive values
           np.array([25.69202253, 21.85734776]),
           # estimated/suggested/initial guess weights, will be refined
           np.array([0.667, 0.333])],
          None,
          None
         ]
    Data_set = []
    output_filename_np = 'Processed data3.csv'
    for i, suffixes in enumerate(suffixes_set):
        # Call the analysis function
        statistics_output = LDA.analyze_lda_data(
                                                 directory_path=directory,
                                                 main_file_name=base_file,
                                                 file_suffixes=suffixes,
                                                 num_components=num_comps,
                                                 vx_range=vx_filter_range[i],
                                                 vy_range=vy_filter_range,
                                                 GMMx_weights = wx[i],
                                                 GMMy_weights = wy
                                                )
        Data_set.append(statistics_output)

    # Convert the list of results to a NumPy array (optional cleanup commented out)
    numpy_array = np.array(Data_set)

    # Save to CSV
    output_file_np = os.path.join(directory, output_filename_np)
    np.savetxt(output_file_np, numpy_array, fmt='%s', delimiter=',')
    print(f"Data saved to {output_filename_np}")
```

### Notes:
- `suffixes_set`: Customize to include the desired data files.
- `num_comps`: Set to 1 for 1D, 2 for 2D measurements.
- Filtering and GMM weights are optional.
- Output is saved as a CSV for further processing.

---
## üìä Output

- Prints computed statistics for each file.
  ```
  ## Sample of output prints
  Statistics for file: TestRun037.xlsx
                          LDA1           LDA2
         Counts           3886           6620
         AT-max        1000.00         999.90
      Data-rate        3886.96        6621.63
              ≈™       232.2454       101.1685
              œÉ        10.0435        13.6422
           Œµ(≈™)         0.3159         0.3287
          Œµ(œÉ·µ§)         0.2234         0.2324
  --------------------------------------------------
  Statistics for file: TestRun038.xlsx
                            LDA1           LDA2
           Counts          10359          20000
           AT-max        1999.78         938.31
        Data-rate        5180.40       21317.17
                ≈™       233.0561       102.5013
                œÉ        10.9698        10.3297
             Œµ(≈™)         0.2113         0.1432
            Œµ(œÉ·µ§)         0.1494         0.1012
  --------------------------------------------------
  
  Full data statistics for points 037 and 038:
                            LDA1           LDA2
           Counts          14245          26620
        Data rate        4749.28       13736.06
                ≈™   232.83391303   102.20150449
                œÉ    10.73005775    11.17476335
   t-distribution         1.9601         1.9601
             Œµ(≈™)     0.17622644     0.13424877
            Œµ(œÉ·µ§)     0.12461091     0.09492821
  ```
- Displays histograms of velocity components.
  ### Sample of output histogram
  <img width="1217" alt="Figure 2025-05-22 094705" src="https://github.com/user-attachments/assets/0629079c-faa8-487f-886b-8760dd39cf62" />
- Optionally uses Gaussian Mixture Model (GMM) responsibilities to compute weighted means and RMS.

## üîß Features

- üìè Velocity range filtering
- üìà GMM-based weighting
- üìä Dual histogram support
- üìâ Confidence interval calculations
- ü©º Outlier removal and row shifting


Ensure `LDA_statistics_v2.py` is in your Python path or working directory.

## üë§ Author

Developed by **Ahmed H. Hanfy**, May 2025.
